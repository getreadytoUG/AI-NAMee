
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.33it/s]
--> Model /media/user/datadisk/LLM_models/Llama-3.2-3B-Instruct
--> /media/user/datadisk/LLM_models/Llama-3.2-3B-Instruct has 3212.749824 Million params
trainable params: 36,700,160 || all params: 3,249,449,984 || trainable%: 1.1294
/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m                                                                   [39m| 0/7 [00:00<?, ?it/s]
--> Training Set Length = 1933
--> Validation Set Length = 2
length of dataset_train 1933
--> Num of Training Set Batches loaded = 966
--> Num of Validation Set Batches loaded = 1
--> Num of Validation Set Batches loaded = 1
Starting epoch 0/30







































































Training Epoch: 1/30, step 965/966 completed (loss: 0.0005792045849375427, lr: 0.0002): : 8it [02:23, 18.00s/it]
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:00<00:00,  2.33it/s]
/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /media/user/datadisk/LLM_models/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
Max CUDA memory allocated was 8 GB
Max CUDA memory reserved was 10 GB
Peak active CUDA memory was 8 GB
CUDA Malloc retries : 0
CPU Total Peak Memory consumed during the train (max): 2 GB
 eval_ppl=tensor(1.0659, device='cuda:0') eval_epoch_loss=tensor(0.0638, device='cuda:0')
we are about to save the PEFT modules
Training Epoch: 2/30, step 5/966 completed (loss: 0.00039635063149034977, lr: 0.00017):   0%|[34m [39m| 0/7 [00:01<?, ?it
PEFT modules are saved in /home/user/eomjimin/AI_Namee/Fine-tuning/lora_output directory
best eval loss on epoch 1 is 0.06381703168153763
Epoch 1: train_perplexity=1.0010, train_epoch_loss=0.0010, epoch time 144.50424756697612s
Starting epoch 1/30




































































Training Epoch: 2/30, step 965/966 completed (loss: 0.0008709192625246942, lr: 0.00017): : 8it [02:17, 17.23s/it]
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:00<00:00,  1.08it/s]
Max CUDA memory allocated was 8 GB
Max CUDA memory reserved was 11 GB
Peak active CUDA memory was 8 GB
CUDA Malloc retries : 0
CPU Total Peak Memory consumed during the train (max): 2 GB
 eval_ppl=tensor(1.0234, device='cuda:0') eval_epoch_loss=tensor(0.0232, device='cuda:0')
we are about to save the PEFT modules
Training Epoch: 3/30, step 1/966 completed (loss: 0.00010588271106826141, lr: 0.000144500
PEFT modules are saved in /home/user/eomjimin/AI_Namee/Fine-tuning/lora_output directory
best eval loss on epoch 2 is 0.023167338222265244
Epoch 2: train_perplexity=1.0003, train_epoch_loss=0.0003, epoch time 138.66739545500604s
Starting epoch 2/30







































































Training Epoch: 3/30, step 965/966 completed (loss: 0.00012584608339238912, lr: 0.00014450000000000002): : 8it [02:23, 17.90s/it]
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:00<00:00,  2.24it/s]
Max CUDA memory allocated was 8 GB
Max CUDA memory reserved was 11 GB
Peak active CUDA memory was 8 GB
CUDA Malloc retries : 0
CPU Total Peak Memory consumed during the train (max): 2 GB
 eval_ppl=tensor(1.0309, device='cuda:0') eval_epoch_loss=tensor(0.0304, device='cuda:0')
Epoch 3: train_perplexity=1.0003, train_epoch_loss=0.0003, epoch time 144.71615308296168s
Starting epoch 3/30
train_config.max_train_step: 0







































































Training Epoch: 4/30, step 965/966 completed (loss: 0.00012386892922222614, lr: 0.00012282500000000002): : 8it [02:25, 18.19s/it]
evaluating Epoch:   0%|[32m                                            [39m| 0/1 [00:00<?, ?it/s]
Max CUDA memory allocated was 8 GB
Max CUDA memory reserved was 10 GB
Peak active CUDA memory was 8 GB
CUDA Malloc retries : 0

evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:00<00:00,  2.35it/s]
 eval_ppl=tensor(1.0227, device='cuda:0') eval_epoch_loss=tensor(0.0225, device='cuda:0')
we are about to save the PEFT modules
PEFT modules are saved in /home/user/eomjimin/AI_Namee/Fine-tuning/lora_output directory
best eval loss on epoch 4 is 0.022459382191300392
Epoch 4: train_perplexity=1.0002, train_epoch_loss=0.0002, epoch time 146.3568825550028s
Starting epoch 4/30
train_config.max_train_step: 0









































































Training Epoch: 5/30, step 958/966 completed (loss: 4.6333298087120056e-05, lr: 0.0001044
Max CUDA memory allocated was 8 GB
Max CUDA memory reserved was 11 GB
Peak active CUDA memory was 8 GB
CUDA Malloc retries : 0
Training Epoch: 5/30, step 965/966 completed (loss: 0.00019698747200891376, lr: 0.00010440125000000001): : 8it [02:29, 18.67s/it]
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:00<00:00,  2.41it/s]
 eval_ppl=tensor(1.0105, device='cuda:0') eval_epoch_loss=tensor(0.0104, device='cuda:0')
we are about to save the PEFT modules
PEFT modules are saved in /home/user/eomjimin/AI_Namee/Fine-tuning/lora_output directory
best eval loss on epoch 5 is 0.010414769873023033
Epoch 5: train_perplexity=1.0002, train_epoch_loss=0.0002, epoch time 149.87503450497752s
Starting epoch 5/30
train_config.max_train_step: 0






































































Training Epoch: 6/30, step 962/966 completed (loss: 7.390118116745725e-05, lr: 8.87410625
Max CUDA memory allocated was 8 GB
Max CUDA memory reserved was 9 GB
Peak active CUDA memory was 8 GB
CUDA Malloc retries : 0
CPU Total Peak Memory consumed during the train (max): 2 GB
 eval_ppl=tensor(1.0150, device='cuda:0') eval_epoch_loss=tensor(0.0149, device='cuda:0')
Epoch 6: train_perplexity=1.0002, train_epoch_loss=0.0002, epoch time 142.24317157902988s
Starting epoch 6/30
Training Epoch: 6/30, step 965/966 completed (loss: 1.499741028965218e-05, lr: 8.87410625e-05): : 8it [02:20, 17.62s/it]
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:00<00:00,  2.43it/s]




































































Training Epoch: 7/30, step 959/966 completed (loss: 3.0576800782000646e-05, lr: 7.5429903
Max CUDA memory allocated was 8 GB
Max CUDA memory reserved was 9 GB
Peak active CUDA memory was 8 GB
CUDA Malloc retries : 0
Training Epoch: 7/30, step 965/966 completed (loss: 3.9869231841294095e-05, lr: 7.5429903125e-05): : 8it [02:19, 17.38s/it]
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:00<00:00,  2.25it/s]
 eval_ppl=tensor(1.0106, device='cuda:0') eval_epoch_loss=tensor(0.0105, device='cuda:0')
Epoch 7: train_perplexity=1.0001, train_epoch_loss=0.0001, epoch time 140.121769082034s
Starting epoch 7/30
train_config.max_train_step: 0






































































Training Epoch: 8/30, step 962/966 completed (loss: 2.6816314857569523e-05, lr: 6.4115417
Max CUDA memory allocated was 8 GB
Max CUDA memory reserved was 9 GB
Peak active CUDA memory was 8 GB
CUDA Malloc retries : 0
Training Epoch: 8/30, step 965/966 completed (loss: 2.646599205036182e-05, lr: 6.411541765624999e-05): : 8it [02:22, 17.76s/it]
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:01<00:00,  1.11s/it]
 eval_ppl=tensor(1.0105, device='cuda:0') eval_epoch_loss=tensor(0.0105, device='cuda:0')
Epoch 8: train_perplexity=1.0001, train_epoch_loss=0.0001, epoch time 143.00532557303086s
Starting epoch 8/30
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:01<00:00,  1.16s/it]






































































Training Epoch: 9/30, step 964/966 completed (loss: 6.529234815388918e-05, lr: 5.44981050
Max CUDA memory allocated was 8 GB
Max CUDA memory reserved was 10 GB
Peak active CUDA memory was 8 GB
CUDA Malloc retries : 0
Training Epoch: 9/30, step 965/966 completed (loss: 5.595826223725453e-05, lr: 5.449810500781249e-05): : 8it [02:21, 17.70s/it]
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:00<00:00,  2.79it/s]
 eval_ppl=tensor(1.0190, device='cuda:0') eval_epoch_loss=tensor(0.0188, device='cuda:0')
Epoch 9: train_perplexity=1.0001, train_epoch_loss=0.0001, epoch time 143.06111871899338s
Starting epoch 9/30
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:00<00:00,  2.33it/s]





































































Training Epoch: 10/30, step 961/966 completed (loss: 1.2252085980435368e-05, lr: 4.632338
Max CUDA memory allocated was 8 GB
Max CUDA memory reserved was 10 GB
Peak active CUDA memory was 8 GB
CUDA Malloc retries : 0
Training Epoch: 10/30, step 965/966 completed (loss: 7.346173515543342e-05, lr: 4.6323389256640616e-05): : 8it [02:19, 17.46s/it]
evaluating Epoch:   0%|[32m                                            [39m| 0/1 [00:00<?, ?it/s]
 eval_ppl=tensor(1.0140, device='cuda:0') eval_epoch_loss=tensor(0.0139, device='cuda:0')
Epoch 10: train_perplexity=1.0001, train_epoch_loss=0.0001, epoch time 140.9002993759932s
Starting epoch 10/30
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:01<00:00,  1.28s/it]







































































Training Epoch: 11/30, step 965/966 completed (loss: 6.2629122112412e-05, lr: 3.9374880868144525e-05): : 8it [02:23, 17.95s/it]
Max CUDA memory allocated was 8 GB
Max CUDA memory reserved was 11 GB
Peak active CUDA memory was 8 GB
CUDA Malloc retries : 0
CPU Total Peak Memory consumed during the train (max): 2 GB
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:01<00:00,  1.02s/it]
 eval_ppl=tensor(1.0093, device='cuda:0') eval_epoch_loss=tensor(0.0093, device='cuda:0')
we are about to save the PEFT modules
PEFT modules are saved in /home/user/eomjimin/AI_Namee/Fine-tuning/lora_output directory
best eval loss on epoch 11 is 0.009272176772356033
Epoch 11: train_perplexity=1.0001, train_epoch_loss=0.0001, epoch time 144.10569162800675s
Starting epoch 11/30
train_config.max_train_step: 0







































































Training Epoch: 12/30, step 963/966 completed (loss: 2.080151352856774e-05, lr: 3.3468648
Max CUDA memory allocated was 8 GB
Max CUDA memory reserved was 11 GB
Peak active CUDA memory was 8 GB
CUDA Malloc retries : 0
Training Epoch: 12/30, step 965/966 completed (loss: 4.1993811464635655e-05, lr: 3.346864873792284e-05): : 8it [02:24, 18.06s/it]
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:00<00:00,  2.35it/s]
 eval_ppl=tensor(1.0132, device='cuda:0') eval_epoch_loss=tensor(0.0131, device='cuda:0')
Epoch 12: train_perplexity=1.0001, train_epoch_loss=0.0001, epoch time 144.97230456903344s
Starting epoch 12/30
train_config.max_train_step: 0
























Training Epoch: 13/30, step 314/966 completed (loss: 0.00013407814549282193, lr: 2.844835Traceback (most recent call last):
  File "/home/user/eomjimin/AI_Namee/Fine-tuning/SFT/llama_recipes/finetuning.py", line 330, in <module>
    fire.Fire(main)
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/fire/core.py", line 143, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/fire/core.py", line 477, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/user/eomjimin/AI_Namee/Fine-tuning/SFT/llama_recipes/finetuning.py", line 309, in main
    results = train(
  File "/home/user/eomjimin/AI_Namee/Fine-tuning/SFT/llama_recipes/utils/train_utils.py", line 176, in train
    loss.backward()
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in backward
    _engine_run_backward(
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/torch/autograd/graph.py", line 768, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt