

Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.03s/it]
--> Model /media/user/datadisk/LLM_models/Llama-3.2-3B-Instruct
--> /media/user/datadisk/LLM_models/Llama-3.2-3B-Instruct has 3212.749824 Million params
/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m                                                     [39m| 0/2 [00:00<?, ?it/s]
--> Training Set Length = 600
--> Validation Set Length = 2
length of dataset_train 600
--> Num of Training Set Batches loaded = 300
--> Num of Validation Set Batches loaded = 1
--> Num of Validation Set Batches loaded = 1
Starting epoch 0/30

















Training Epoch: 1/30, step 299/300 completed (loss: 0.056199811398983, lr: 0.0002): : 3it [00:34, 11.67s/it]
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[39m| 1/1 [00:00<00:00,  2.85it/s]
Traceback (most recent call last):
  File "/home/user/eomjimin/AI_Namee/Fine-tuning/SFT/llama_recipes/finetuning.py", line 329, in <module>
    fire.Fire(main)
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/fire/core.py", line 143, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/fire/core.py", line 477, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/user/eomjimin/AI_Namee/Fine-tuning/SFT/llama_recipes/finetuning.py", line 308, in main
    results = train(
  File "/home/user/eomjimin/AI_Namee/Fine-tuning/SFT/llama_recipes/utils/train_utils.py", line 252, in train
    save_model_checkpoint(model, train_config.output_dir)
  File "/home/user/eomjimin/AI_Namee/Fine-tuning/SFT/llama_recipes/model_checkpointing/checkpoint_handler.py", line 289, in save_model_checkpoint
    torch.save(state_dict, output_file)
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/torch/serialization.py", line 651, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/torch/serialization.py", line 525, in _open_zipfile_writer
    return container(name_or_buffer)
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/torch/serialization.py", line 496, in __init__
    super().__init__(torch._C.PyTorchFileWriter(self.name))
RuntimeError: Parent directory output/llama3.2-SFT-lora7(test) does not exist.
Max CUDA memory allocated was 29 GB
Max CUDA memory reserved was 31 GB
Peak active CUDA memory was 29 GB
CUDA Malloc retries : 0
CPU Total Peak Memory consumed during the train (max): 2 GB
 eval_ppl=tensor(1880.0460, device='cuda:0') eval_epoch_loss=tensor(7.5391, device='cuda:0')