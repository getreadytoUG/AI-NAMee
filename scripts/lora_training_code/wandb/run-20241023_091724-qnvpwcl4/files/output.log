Traceback (most recent call last):
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/media/user/datadisk/LLM_models/Llama-3.2-3B-Instruct'. Use `repo_type` argument if needed.
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/home/user/eomjimin/AI_Namee/Fine-tuning/SFT/llama_recipes/finetuning.py", line 330, in <module>
    fire.Fire(main)
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/fire/core.py", line 143, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/fire/core.py", line 477, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/fire/core.py", line 693, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/user/eomjimin/AI_Namee/Fine-tuning/SFT/llama_recipes/finetuning.py", line 124, in main
    config = AutoConfig.from_pretrained(train_config.model_name)
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1006, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/transformers/configuration_utils.py", line 570, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/transformers/configuration_utils.py", line 629, in _get_config_dict
    resolved_config_file = cached_file(
  File "/home/user/anaconda3/envs/llm-api/lib/python3.10/site-packages/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: '/media/user/datadisk/LLM_models/Llama-3.2-3B-Instruct'. Please provide either the path to a local folder or the repo_id of a model on the Hub.